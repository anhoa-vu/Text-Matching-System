{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe\n",
    "import pandas as pd\n",
    "\n",
    "#computation\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#NLP lib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# string operations\n",
    "import string \n",
    "import re\n",
    "\n",
    "# general imports\n",
    "import math\n",
    "\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#others\n",
    "import collections\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from itertools import islice\n",
    "from itertools import chain\n",
    "import pickle\n",
    "\n",
    "#pre-build package\n",
    "from utils import *\n",
    "from Invertedfile_TFIDF import Invertedfile_TFIDF\n",
    "\n",
    "#auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
      "/opt/anaconda3/envs/nlp_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222.0</td>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360472</td>\n",
       "      <td>364011</td>\n",
       "      <td>490273.0</td>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183004</td>\n",
       "      <td>279958</td>\n",
       "      <td>279959.0</td>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1      qid2  \\\n",
       "0  133273  213221  213222.0   \n",
       "1  402555  536040  536041.0   \n",
       "2  360472  364011  490273.0   \n",
       "3  150662  155721    7256.0   \n",
       "4  183004  279958  279959.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  How is the life of a math student? Could you d...   \n",
       "1                How do I control my horny emotions?   \n",
       "2       What causes stool color to change to yellow?   \n",
       "3                        What can one do after MBBS?   \n",
       "4  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Which level of prepration is enough for the ex...           0.0  \n",
       "1                 How do you control your horniness?           1.0  \n",
       "2  What can cause stool to come out as little balls?           0.0  \n",
       "3                       What do i do after my MBBS ?           1.0  \n",
       "4  Would a second airport in Sydney, Australia be...           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.tsv', sep='\\t',error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              232203\n",
       "qid1            232203\n",
       "qid2            232202\n",
       "question1       232203\n",
       "question2       232203\n",
       "is_duplicate         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "#drop rows with dupplication\n",
    "df = df.drop_duplicates(subset = ['question1'], keep = 'last')\n",
    "df = df.drop_duplicates(subset = ['question2'], keep = 'last')\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>11568</td>\n",
       "      <td>22332</td>\n",
       "      <td>22333.0</td>\n",
       "      <td>Which is the best book to study TENSOR for gen...</td>\n",
       "      <td>Which is the best book for tensor calculus?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>33995</td>\n",
       "      <td>62359</td>\n",
       "      <td>62360.0</td>\n",
       "      <td>How does an IQ test work and what is determine...</td>\n",
       "      <td>How does IQ test works?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>244506</td>\n",
       "      <td>357159</td>\n",
       "      <td>357160.0</td>\n",
       "      <td>Is it safe to use Xiaomi mobile phones?</td>\n",
       "      <td>Is it safe or unsafe to use Xiaomi Products?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27</td>\n",
       "      <td>375073</td>\n",
       "      <td>506056</td>\n",
       "      <td>506057.0</td>\n",
       "      <td>What are the best books on cosmology?</td>\n",
       "      <td>Which is the best book for cosmology?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      id    qid1      qid2  \\\n",
       "1       1  402555  536040  536041.0   \n",
       "6      13   11568   22332   22333.0   \n",
       "11     24   33995   62359   62360.0   \n",
       "12     25  244506  357159  357160.0   \n",
       "14     27  375073  506056  506057.0   \n",
       "\n",
       "                                            question1  \\\n",
       "1                 How do I control my horny emotions?   \n",
       "6   Which is the best book to study TENSOR for gen...   \n",
       "11  How does an IQ test work and what is determine...   \n",
       "12            Is it safe to use Xiaomi mobile phones?   \n",
       "14              What are the best books on cosmology?   \n",
       "\n",
       "                                       question2  is_duplicate  \n",
       "1             How do you control your horniness?           1.0  \n",
       "6    Which is the best book for tensor calculus?           1.0  \n",
       "11                       How does IQ test works?           1.0  \n",
       "12  Is it safe or unsafe to use Xiaomi Products?           1.0  \n",
       "14         Which is the best book for cosmology?           1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the first 100 \"is duplicate\" rows for testing\n",
    "df_test = df[df['is_duplicate'] == 1].iloc[:100]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_ques2'] = df.question2.apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF with Inverted File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build vocabulary...\n",
      "Build TF-IDF matrix...\n",
      "Build inverted file...\n",
      "Model is ready to query!\n"
     ]
    }
   ],
   "source": [
    "model1 = Invertedfile_TFIDF(df[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k = 2:  0.9\n",
      "Accuracy wit k = 5:  0.97\n"
     ]
    }
   ],
   "source": [
    "top2  = model1.accuracy(df_test, 2) \n",
    "top5  = model1.accuracy(df_test, 5) \n",
    "\n",
    "print(\"Accuracy with k = 2: \", top2)\n",
    "print(\"Accuracy wit k = 5: \", top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your query is: level\n",
      " What is the difference between user level and kernel level threads? - 2.6552614282206957\n",
      "-----------------------------------------------------\n",
      " Why all the semiconductor have same Fermi level? - 2.6552614282206957\n",
      "-----------------------------------------------------\n",
      " What is the purpose of philosophy on an educational level? - 1.9914460711655217\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model1.query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove_embedding = load_glove_model('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0076543,  0.93456  , -0.73189  , -0.55162  ,  0.76977  ,\n",
       "        0.35925  , -1.1365   , -1.1632   ,  0.34214  ,  0.29145  ,\n",
       "       -0.8711   ,  0.9197   , -0.47069  , -0.22834  ,  1.4777   ,\n",
       "       -0.81714  , -0.17466  , -0.51093  , -0.28354  ,  0.23292  ,\n",
       "        0.71832  ,  0.23414  ,  0.49443  ,  0.35483  ,  0.76889  ,\n",
       "       -1.4374   , -1.7457   , -0.28994  , -0.10156  , -0.36959  ,\n",
       "        2.5502   , -1.0581   , -0.049416 , -0.25524  , -0.63303  ,\n",
       "        0.02671  , -0.18733  ,  0.20206  , -0.26288  , -0.41418  ,\n",
       "        0.83473  , -0.14227  , -0.28125  ,  0.098155 , -0.17096  ,\n",
       "        0.52408  ,  0.31851  , -0.089847 , -0.27223  , -0.0088736])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding['book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the average word based sentence embedding\n",
    "def averaging(query) -> np.array:\n",
    "    words_list = nltk.word_tokenize(query)\n",
    "    length = 0 \n",
    "    \n",
    "    for word in words_list:\n",
    "      if word in glove_embedding:\n",
    "        length = length + 1         # calculate length of input query\n",
    "    query_emb = []\n",
    "    glove_index = []\n",
    "\n",
    "    for word in words_list:    \n",
    "      if word in glove_embedding: # check if word is present in glove embedding\n",
    "        glove_index.append (glove_embedding[word])\n",
    "    \n",
    "    score = []\n",
    "    if (length >= 1):             # if query has at least one word\n",
    "      glove_index = np.array(glove_index)\n",
    "\n",
    "      for i in range(0, 50):\n",
    "        sum = 0\n",
    "        for j in range(0, length ):\n",
    "          elem = glove_index[j][i] # get value from word embedding\n",
    "          sum = sum + elem\n",
    "\n",
    "        score.append(sum)\n",
    "\n",
    "      score = np.array(score)\n",
    "    \n",
    "      for elem in score:\n",
    "        elem = float(elem/length) # divide by length of query to calculate average\n",
    "        query_emb.append(elem)\n",
    "\n",
    "      query_emb = np.array(query_emb)\n",
    "\n",
    "    else:\n",
    "      query_emb = np.zeros(100)\n",
    "\n",
    "    return query_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def neg_distance(pt1, pt2):\n",
    "    sum_sq = np.sum(np.square(pt1 - pt2))\n",
    "    return -np.sqrt(sum_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function to caculate cosine similarity between two vectors v1 and v2\n",
    "# def cosine(v1, v2):\n",
    "\n",
    "#     v1 = np.array(v1)\n",
    "#     v2 = np.array(v2)\n",
    "    \n",
    "#     denominator = (np.sqrt(np.sum(v1**2)) * np.sqrt(np.sum(v2**2)))\n",
    "\n",
    "#     if  denominator != 0:\n",
    "#       cos = float ( (np.dot(v1, v2)) / denominator )\n",
    "#     else:\n",
    "#       cos = -1.0 # lowest val of cos theata\n",
    "\n",
    "#     return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-5e570034b2f4>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  average_enbedding = np.array(vec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = []\n",
    "\n",
    "for ques in (df['processed_ques2'][0:5000]): \n",
    "  val = averaging(ques ) \n",
    "  vec.append(val)\n",
    "\n",
    "# store word average sentence embedding\n",
    "average_enbedding = np.array(vec) \n",
    "average_enbedding.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return top k document indices and scores\n",
    "def get_similarity_avg_word(input, k) :\n",
    "\n",
    "  input = text_preprocessing(input) # preprocess input text\n",
    "\n",
    "  val_input = averaging(input)\n",
    "\n",
    "  cosine_similarities = []\n",
    "  doc_simi = {}\n",
    "\n",
    "  i = 0\n",
    "  for x in average_enbedding:\n",
    "    try:\n",
    "      sim_calculation = neg_distance(val_input,x)\n",
    "    except:\n",
    "      sim_calculation = -99\n",
    "    cosine_similarities.append(sim_calculation)\n",
    "    doc_simi[i] = sim_calculation \n",
    "    i = i + 1\n",
    "  \n",
    "  sorted_sim = sorted(doc_simi.items(), key = lambda kv:(kv[1], kv[0]),reverse = True ) # sort by value\n",
    "  topk = sorted_sim[0:k]\n",
    "\n",
    "  return   topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_k(k: list):\n",
    "  \"\"\"\n",
    "  function to print top k similar document\n",
    "  \"\"\"\n",
    "  for i in k :\n",
    "    val = i[0]\n",
    "    score = i[1]\n",
    "    sentence = df['question2'][val]\n",
    "    print(\" {}, Score: {}\".format( sentence, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the best websites for entrepreneurs?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question1'][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Since the nose has a breathing function, why does the mouth have a breathing function too? Is it redundant?, Score: -2.021339601787883\n",
      " How much time does the stomach take to send the first particles of chyme to the small intestine?, Score: -2.0919111153375307\n",
      " How do I reduce eye strain and headache while working on a computer?, Score: -2.134440984733282\n",
      " How do you slow down your digestive system?, Score: -2.1381674058986175\n",
      " If Einstein's theory of general relativity says that gravity is the result of curved spacetime and that matter, such as a planet, has no force whatsoever that pulls other matter towards it, how are we able to walk on the Earth without falling off? Is there a force pushing on us?, Score: -2.2206410086485895\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top5 = get_similarity_avg_word(\"how to control my gut\" , 5 )\n",
    "print_top_k(top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df: pd.DataFrame, k):\n",
    "    \"\"\"\n",
    "    function to perform inverted file TFIDF in for each row and return the accuracy\n",
    "    :params:\n",
    "        df: Test dataframe\n",
    "        k: number of similar documents\n",
    "    \"\"\"\n",
    "    tmp = 0\n",
    "    for i in df.index: # for each row\n",
    "        query = df['question1'][df.index == i].values[0]\n",
    "        ques_sim = get_similarity_avg_word(query,k)\n",
    "        for q in ques_sim: #for each similar question\n",
    "            if q[0] == i:\n",
    "                tmp += 1\n",
    "                break\n",
    "    return tmp/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted matches in top2:  0.86\n",
      "Correctly predicted matches in top5:  0.86\n"
     ]
    }
   ],
   "source": [
    "accuracy_top2  = accuracy(df_test, 2) # top 2\n",
    "accuracy_top5  = accuracy(df_test, 5) # top 5\n",
    " \n",
    "print(\"Correctly predicted matches in top2: \", accuracy_top2)\n",
    "print(\"Correctly predicted matches in top5: \", accuracy_top5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AverageWordEmbedding import AverageWordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model...\n",
      "Embedding All Question 2 data...\n",
      "Model is ready to query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MACOS/Documents/Learning/Adelaide/NLP/Text-Matching-System/AverageWordEmbedding.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self.q2_embedding = np.array(vec) # store average word embedding of all question 2\n"
     ]
    }
   ],
   "source": [
    "model2 = AverageWordEmbedding('glove.6B.50d.txt', 50, df[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.accuracy(df_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your query is: How to surf\n",
      " How do I train my cat to be a outdoor cat? - -3.504344720578614\n",
      "-----------------------------------------------------\n",
      " Is it safe to swim in the ocean at night? - -3.804269284652978\n",
      "-----------------------------------------------------\n",
      " Why does my Virtual DJ keeps crashing? - -3.866685477161496\n",
      "-----------------------------------------------------\n",
      " How do websites like The Pirate Bay survive? - -3.9553926728751576\n",
      "-----------------------------------------------------\n",
      " What is Paradise like? - -3.974708603592936\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model2.query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the average word based sentence embedding\n",
    "def averaging2(query) -> np.array:\n",
    "    words_list = nltk.word_tokenize(query)\n",
    "    length = 0 \n",
    "    \n",
    "    for word in words_list:\n",
    "      if word in glove_embedding:\n",
    "        length = length + 1         # calculate length of input query\n",
    "    query_emb = []\n",
    "    glove_index = []\n",
    "\n",
    "    for word in words_list:    \n",
    "      if word in glove_embedding: # check if word is present in glove embedding\n",
    "        glove_index.append (glove_embedding[word])\n",
    "    try:\n",
    "        tmp = sum(glove_index)/length\n",
    "    except:\n",
    "        tmp = np.zeros(50)\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4, 1.8, 2.2, 2.6, 3. ])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.array([1,2,3,4,5])\n",
    "arr2 = np.array([6,7,8,9,10])\n",
    "(arr1 + arr2)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.438865  , -0.26961825,  0.0690625 , -0.264885  ,  0.3105475 ,\n",
       "        0.20371275,  0.1025725 ,  0.1583975 ,  0.236895  , -0.02950025,\n",
       "        0.16521575,  0.3717595 , -0.43017   ,  0.0503195 ,  0.08789875,\n",
       "        0.4204225 , -0.07227   , -0.13617275,  0.14628975, -0.385215  ,\n",
       "       -0.128125  ,  0.265722  ,  0.2042175 , -0.21258835,  0.4479985 ,\n",
       "       -1.7739625 , -0.4907435 ,  0.029605  ,  0.51749   , -0.3682475 ,\n",
       "        3.047975  ,  0.5068575 , -0.5717475 , -0.03427   , -0.4175875 ,\n",
       "        0.0467725 ,  0.054175  ,  0.24339525,  0.604275  , -0.21218   ,\n",
       "       -0.01801825, -0.075164  , -0.1553185 ,  0.4495775 , -0.08939975,\n",
       "        0.090298  ,  0.1472285 , -0.33631175,  0.030483  ,  0.0696875 ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaging2('How to control my gut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.438865  , -0.26961825,  0.0690625 , -0.264885  ,  0.3105475 ,\n",
       "        0.20371275,  0.1025725 ,  0.1583975 ,  0.236895  , -0.02950025,\n",
       "        0.16521575,  0.3717595 , -0.43017   ,  0.0503195 ,  0.08789875,\n",
       "        0.4204225 , -0.07227   , -0.13617275,  0.14628975, -0.385215  ,\n",
       "       -0.128125  ,  0.265722  ,  0.2042175 , -0.21258835,  0.4479985 ,\n",
       "       -1.7739625 , -0.4907435 ,  0.029605  ,  0.51749   , -0.3682475 ,\n",
       "        3.047975  ,  0.5068575 , -0.5717475 , -0.03427   , -0.4175875 ,\n",
       "        0.0467725 ,  0.054175  ,  0.24339525,  0.604275  , -0.21218   ,\n",
       "       -0.01801825, -0.075164  , -0.1553185 ,  0.4495775 , -0.08939975,\n",
       "        0.090298  ,  0.1472285 , -0.33631175,  0.030483  ,  0.0696875 ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaging('How to control my gut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9be210f112d3bd93a6327b459217e15105c4405a02aec2765b09f959417e942a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('nlp_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
